{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "MNIST Conditional GAN (CGAN) Exercise - Student Version\n",
        "Welcome to this hands-on exercise on Conditional Generative Adversarial Networks! You'll build a CGAN that can generate specific digits (0-9) on command.\n",
        "Learning Objectives\n",
        "\n",
        "Understand the difference between GANs and Conditional GANs\n",
        "Learn how to incorporate class labels into both Generator and Discriminator\n",
        "Implement label embedding and concatenation techniques\n",
        "Generate specific digits on demand\n",
        "Analyze the quality and diversity of conditional generation\n",
        "\n",
        "What makes CGANs special?\n",
        "Unlike regular GANs that generate random samples, Conditional GANs let you control what gets generated by providing additional information (conditions) like class labels, text descriptions, or other attributes.\n"
      ],
      "metadata": {
        "id": "sPXksRDVqcQP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDMlHfyHqXKV",
        "outputId": "4de4d610-ab58-4dec-eaa0-28defe5e9e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transforms for MNIST data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # TODO: Add normalization transform to scale pixel values to [-1, 1]\n",
        "    # YOUR CODE HERE:\n",
        "\n",
        "])\n",
        "\n",
        "# TODO: Load MNIST dataset (keep labels this time!)\n",
        "# YOUR CODE HERE:\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root='/content/', train=True, download=True, transform=None\n",
        ")\n",
        "\n",
        "# Create data loader\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Dataset information\n",
        "num_classes = 10  # Digits 0-9\n",
        "print(f\"Dataset size: {len(train_dataset)}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Number of batches: {len(train_loader)}\")\n",
        "\n",
        "# Let's visualize some samples with their labels\n",
        "def visualize_dataset_samples():\n",
        "    # Get a batch of data\n",
        "    data_iter = iter(train_loader)\n",
        "    images, labels = next(data_iter)\n",
        "\n",
        "    # Plot first 10 images with labels\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(images[i].squeeze(), cmap='gray')\n",
        "        ax.set_title(f'Label: {labels[i].item()}')\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.suptitle('MNIST Dataset Samples with Labels')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_dataset_samples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "u8pufardqu7A",
        "outputId": "2849f97b-d4e7-4929-a085-df65ab591539"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'transforms' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-2862384917.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m transform = transforms.Compose([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# TODO: Add normalization transform to scale pixel values to [-1, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Hint: Use transforms.Normalize with mean=0.5, std=0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# YOUR CODE HERE:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    Converts class labels into dense vector representations\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes, embedding_dim):\n",
        "        super(LabelEmbedding, self).__init__()\n",
        "        # TODO: Create an embedding layer\n",
        "        # Hint: Use nn.Embedding(num_classes, embedding_dim)\n",
        "        # YOUR CODE HERE:\n",
        "        self.embedding =\n",
        "\n",
        "    def forward(self, labels):\n",
        "        # TODO: Apply embedding to labels\n",
        "        # YOUR CODE HERE:\n",
        "        return\n",
        "\n",
        "# Test the embedding layer\n",
        "embedding_dim = 50\n",
        "label_embedding = LabelEmbedding(num_classes, embedding_dim)\n",
        "\n",
        "# Test with some sample labels\n",
        "sample_labels = torch.tensor([0, 1, 2, 3, 4])\n",
        "embedded = label_embedding(sample_labels)\n",
        "print(f\"Original labels shape: {sample_labels.shape}\")\n",
        "print(f\"Embedded labels shape: {embedded.shape}\")\n",
        "print(f\"Each label becomes a {embedding_dim}-dimensional vector\")"
      ],
      "metadata": {
        "id": "uPgtx0V0rqgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConditionalGenerator(nn.Module):\n",
        "    def __init__(self, noise_dim=100, num_classes=10, embedding_dim=50, img_dim=28*28):\n",
        "        super(ConditionalGenerator, self).__init__()\n",
        "\n",
        "        # TODO: Create label embedding layer\n",
        "        # YOUR CODE HERE:\n",
        "        self.label_embedding =\n",
        "\n",
        "        # Calculate input dimension: noise + embedded label\n",
        "        # TODO: Calculate the total input dimension\n",
        "        # YOUR CODE HERE:\n",
        "        input_dim =\n",
        "\n",
        "        # TODO: Define the generator network\n",
        "        # Architecture: input_dim -> 256 -> 512 -> 1024 -> img_dim\n",
        "        # YOUR CODE HERE:\n",
        "        self.model = nn.Sequential(\n",
        "            # Layer 1: input_dim -> 256\n",
        "            # Hint: Use nn.Linear followed by nn.LeakyReLU(0.2)\n",
        "\n",
        "            # Layer 2: 256 -> 512\n",
        "\n",
        "            # Layer 3: 512 -> 1024\n",
        "\n",
        "            # Output layer: 1024 -> img_dim\n",
        "            # Use Tanh activation for final layer\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        # TODO: Implement forward pass\n",
        "        # Steps:\n",
        "        # 1. Embed the labels\n",
        "        # 2. Concatenate noise and embedded labels\n",
        "        # 3. Pass through the network\n",
        "        # YOUR CODE HERE:\n",
        "\n",
        "        pass"
      ],
      "metadata": {
        "id": "Rj4WBvG-sIPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConditionalDiscriminator(nn.Module):\n",
        "    def __init__(self, img_dim=28*28, num_classes=10, embedding_dim=50):\n",
        "        super(ConditionalDiscriminator, self).__init__()\n",
        "\n",
        "        # TODO: Create label embedding layer\n",
        "        # YOUR CODE HERE:\n",
        "        self.label_embedding =\n",
        "\n",
        "        # Calculate input dimension: image + embedded label\n",
        "        # TODO: Calculate the total input dimension\n",
        "        # YOUR CODE HERE:\n",
        "        input_dim =\n",
        "\n",
        "        # TODO: Define the discriminator network\n",
        "        # Architecture: input_dim -> 1024 -> 512 -> 256 -> 1\n",
        "        # YOUR CODE HERE:\n",
        "        self.model = nn.Sequential(\n",
        "            # Layer 1: input_dim -> 1024\n",
        "            # Hint: Use nn.Linear, nn.LeakyReLU(0.2), nn.Dropout(0.3)\n",
        "\n",
        "            # Layer 2: 1024 -> 512\n",
        "\n",
        "            # Layer 3: 512 -> 256\n",
        "\n",
        "            # Output layer: 256 -> 1\n",
        "            # Use Sigmoid for binary classification\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, images, labels):\n",
        "        # TODO: Implement forward pass\n",
        "        # Steps:\n",
        "        # 1. Flatten images if needed\n",
        "        # 2. Embed the labels\n",
        "        # 3. Concatenate images and embedded labels\n",
        "        # 4. Pass through the network\n",
        "        # YOUR CODE HERE:\n",
        "\n",
        "        pass"
      ],
      "metadata": {
        "id": "nE2aR_JpsvOh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "fba179f9-c1df-42a8-c3a4-8918109fc3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-9-1062803426.py, line 7)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-9-1062803426.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    generator =\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "noise_dim = 100\n",
        "embedding_dim = 50\n",
        "learning_rate = 0.0002\n",
        "\n",
        "# TODO: Create instances of Generator and Discriminator\n",
        "# YOUR CODE HERE:\n",
        "generator =\n",
        "discriminator =\n",
        "\n",
        "# Move models to device\n",
        "generator.to(device)\n",
        "discriminator.to(device)\n",
        "\n",
        "# TODO: Define loss function and optimizers\n",
        "# YOUR CODE HERE:\n",
        "criterion =\n",
        "gen_optimizer =\n",
        "disc_optimizer =\n",
        "\n",
        "print(\"Models initialized successfully!\")\n",
        "print(f\"Generator parameters: {sum(p.numel() for p in generator.parameters())}\")\n",
        "print(f\"Discriminator parameters: {sum(p.numel() for p in discriminator.parameters())}\")\n",
        "\n",
        "# Test the networks with dummy data\n",
        "test_noise = torch.randn(5, noise_dim).to(device)\n",
        "test_labels = torch.randint(0, num_classes, (5,)).to(device)\n",
        "test_images = torch.randn(5, 28*28).to(device)\n",
        "\n",
        "print(f\"\\nTesting networks:\")\n",
        "print(f\"Generator output shape: {generator(test_noise, test_labels).shape}\")\n",
        "print(f\"Discriminator output shape: {discriminator(test_images, test_labels).shape}\")"
      ],
      "metadata": {
        "id": "sGv-GULptAjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_conditional_gan(generator, discriminator, train_loader, num_epochs=50):\n",
        "    \"\"\"\n",
        "    Train the Conditional GAN for specified number of epochs\n",
        "    \"\"\"\n",
        "\n",
        "    # Lists to store losses for plotting\n",
        "    gen_losses = []\n",
        "    disc_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        gen_epoch_loss = 0\n",
        "        disc_epoch_loss = 0\n",
        "\n",
        "        for batch_idx, (real_images, real_labels) in enumerate(train_loader):\n",
        "            batch_size = real_images.size(0)\n",
        "\n",
        "            # Flatten images and move to device\n",
        "            real_images = real_images.view(batch_size, -1).to(device)\n",
        "            real_labels = real_labels.to(device)\n",
        "\n",
        "            # Create binary labels for real/fake classification\n",
        "            # TODO: Create real and fake binary labels\n",
        "            # YOUR CODE HERE:\n",
        "            real_binary_labels =\n",
        "            fake_binary_labels =\n",
        "\n",
        "            # =================================================================\n",
        "            # TRAIN DISCRIMINATOR\n",
        "            # =================================================================\n",
        "\n",
        "            disc_optimizer.zero_grad()\n",
        "\n",
        "            # Train on real images with their true labels\n",
        "            # TODO: Get discriminator output for real images and calculate loss\n",
        "            # YOUR CODE HERE:\n",
        "            real_output =\n",
        "            real_loss =\n",
        "\n",
        "            # Train on fake images with random labels\n",
        "            # TODO: Generate fake images with random labels\n",
        "            # YOUR CODE HERE:\n",
        "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
        "            fake_labels = torch.randint(0, num_classes, (batch_size,)).to(device)\n",
        "            fake_images =\n",
        "            fake_output =\n",
        "            fake_loss =\n",
        "\n",
        "            # Total discriminator loss\n",
        "            # TODO: Calculate total discriminator loss and backpropagate\n",
        "            # YOUR CODE HERE:\n",
        "            disc_loss =\n",
        "            disc_loss.backward()\n",
        "            disc_optimizer.step()\n",
        "\n",
        "            # =================================================================\n",
        "            # TRAIN GENERATOR\n",
        "            # =================================================================\n",
        "\n",
        "            gen_optimizer.zero_grad()\n",
        "\n",
        "            # TODO: Train generator to fool discriminator\n",
        "            # Generate fake images and try to make discriminator classify them as real\n",
        "            # YOUR CODE HERE:\n",
        "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
        "            gen_labels = torch.randint(0, num_classes, (batch_size,)).to(device)\n",
        "            fake_images =\n",
        "            fake_output =\n",
        "            gen_loss =\n",
        "\n",
        "            gen_loss.backward()\n",
        "            gen_optimizer.step()\n",
        "\n",
        "            # Accumulate losses\n",
        "            gen_epoch_loss += gen_loss.item()\n",
        "            disc_epoch_loss += disc_loss.item()\n",
        "\n",
        "        # Average losses for the epoch\n",
        "        gen_epoch_loss /= len(train_loader)\n",
        "        disc_epoch_loss /= len(train_loader)\n",
        "\n",
        "        gen_losses.append(gen_epoch_loss)\n",
        "        disc_losses.append(disc_epoch_loss)\n",
        "\n",
        "        # Print progress\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "            print(f'Generator Loss: {gen_epoch_loss:.4f}')\n",
        "            print(f'Discriminator Loss: {disc_epoch_loss:.4f}')\n",
        "            print('-' * 50)\n",
        "\n",
        "    return gen_losses, disc_losses"
      ],
      "metadata": {
        "id": "he43WhO7tBIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(gen_losses, disc_losses):\n",
        "    \"\"\"Plot training losses\"\"\"\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(gen_losses, label='Generator Loss')\n",
        "    plt.plot(disc_losses, label='Discriminator Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Conditional GAN Training Losses')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def generate_specific_digits(generator, digits_to_generate, num_samples_per_digit=5):\n",
        "    \"\"\"Generate specific digits on demand\"\"\"\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        # TODO: Generate images for specific digit classes\n",
        "        # YOUR CODE HERE:\n",
        "        all_images = []\n",
        "        all_labels = []\n",
        "\n",
        "        for digit in digits_to_generate:\n",
        "            # Create noise and labels for this digit\n",
        "            noise =\n",
        "            labels =\n",
        "\n",
        "            # Generate images\n",
        "            fake_images =\n",
        "\n",
        "            all_images.append(fake_images)\n",
        "            all_labels.extend([digit] * num_samples_per_digit)\n",
        "\n",
        "        # Concatenate all images\n",
        "        all_images = torch.cat(all_images, dim=0)\n",
        "        all_images = all_images.view(-1, 28, 28).cpu().numpy()\n",
        "\n",
        "        # Plot results\n",
        "        num_digits = len(digits_to_generate)\n",
        "        fig, axes = plt.subplots(num_digits, num_samples_per_digit,\n",
        "                                figsize=(num_samples_per_digit*2, num_digits*2))\n",
        "\n",
        "        if num_digits == 1:\n",
        "            axes = axes.reshape(1, -1)\n",
        "\n",
        "        for i, digit in enumerate(digits_to_generate):\n",
        "            for j in range(num_samples_per_digit):\n",
        "                idx = i * num_samples_per_digit + j\n",
        "                axes[i, j].imshow(all_images[idx], cmap='gray')\n",
        "                axes[i, j].set_title(f'Generated {digit}')\n",
        "                axes[i, j].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def generate_all_digits(generator, num_samples_per_digit=8):\n",
        "    \"\"\"Generate samples for all digit classes (0-9)\"\"\"\n",
        "    # TODO: Generate samples for each digit class\n",
        "    # YOUR CODE HERE:\n",
        "    digits_to_generate = list(range(10))  # 0, 1, 2, ..., 9\n",
        "    generate_specific_digits(generator, digits_to_generate, num_samples_per_digit)\n",
        "\n",
        "def compare_conditional_vs_real(train_loader, generator):\n",
        "    \"\"\"Compare real and conditionally generated images\"\"\"\n",
        "    # Get real images and labels\n",
        "    real_images, real_labels = next(iter(train_loader))\n",
        "\n",
        "    # TODO: Generate fake images with the same labels as real images\n",
        "    # YOUR CODE HERE:\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        noise =\n",
        "        fake_images =\n",
        "        fake_images = fake_images.view(-1, 28, 28)\n",
        "\n",
        "    # Plot comparison for first 10 samples\n",
        "    fig, axes = plt.subplots(2, 10, figsize=(15, 4))\n",
        "\n",
        "    for i in range(10):\n",
        "        # Real images\n",
        "        axes[0, i].imshow(real_images[i].squeeze(), cmap='gray')\n",
        "        axes[0, i].set_title(f'Real {real_labels[i].item()}')\n",
        "        axes[0, i].axis('off')\n",
        "\n",
        "        # Generated images\n",
        "        axes[1, i].imshow(fake_images[i].cpu().numpy(), cmap='gray')\n",
        "        axes[1, i].set_title(f'Generated {real_labels[i].item()}')\n",
        "        axes[1, i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OICCuPLPtO8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting Conditional GAN training...\")\n",
        "print(\"This may take several minutes depending on your hardware.\")\n",
        "\n",
        "# TODO: Train the conditional GAN\n",
        "# YOUR CODE HERE:\n",
        "gen_losses, disc_losses =\n",
        "\n",
        "print(\"Training completed!\")"
      ],
      "metadata": {
        "id": "N7T7-ClYwt11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_digit_generation(generator):\n",
        "    \"\"\"\n",
        "    Interactive function to generate any digit on demand\n",
        "    \"\"\"\n",
        "    print(\"Interactive Digit Generation!\")\n",
        "    print(\"Enter digits (0-9) separated by spaces, or 'quit' to exit\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nWhich digits would you like to generate? \")\n",
        "\n",
        "        if user_input.lower() == 'quit':\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            # Parse user input\n",
        "            digits = [int(d) for d in user_input.split() if d.isdigit() and 0 <= int(d) <= 9]\n",
        "\n",
        "            if not digits:\n",
        "                print(\"Please enter valid digits (0-9)\")\n",
        "                continue\n",
        "\n",
        "            print(f\"Generating digits: {digits}\")\n",
        "            generate_specific_digits(generator, digits, num_samples_per_digit=4)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}. Please enter digits separated by spaces.\")\n",
        "\n",
        "# Uncomment to run interactive generation\n",
        "# interactive_digit_generation(generator)"
      ],
      "metadata": {
        "id": "36q8jXu0wvZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_conditional_generation(generator, num_samples=100):\n",
        "    \"\"\"\n",
        "    Evaluate the quality and diversity of conditional generation\n",
        "    \"\"\"\n",
        "    generator.eval()\n",
        "\n",
        "    # Generate samples for each class\n",
        "    class_samples = {i: [] for i in range(10)}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for digit in range(10):\n",
        "            noise = torch.randn(num_samples, noise_dim).to(device)\n",
        "            labels = torch.full((num_samples,), digit, dtype=torch.long).to(device)\n",
        "            fake_images = generator(noise, labels)\n",
        "            fake_images = fake_images.view(num_samples, 28, 28).cpu().numpy()\n",
        "            class_samples[digit] = fake_images\n",
        "\n",
        "    # TODO: Calculate diversity within each class\n",
        "    # Hint: You could calculate pixel-wise variance or other diversity metrics\n",
        "    # YOUR CODE HERE:\n",
        "\n",
        "    # Plot some statistics\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "\n",
        "    for digit in range(10):\n",
        "        row = digit // 5\n",
        "        col = digit % 5\n",
        "\n",
        "        # Calculate mean image for this digit\n",
        "        mean_image = np.mean(class_samples[digit], axis=0)\n",
        "        axes[row, col].imshow(mean_image, cmap='gray')\n",
        "        axes[row, col].set_title(f'Mean Generated {digit}')\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "    plt.suptitle('Mean Generated Images for Each Digit Class')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return class_samples\n",
        "\n",
        "# Run evaluation\n",
        "class_samples = evaluate_conditional_generation(generator)"
      ],
      "metadata": {
        "id": "pcMbNO4aww90"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}