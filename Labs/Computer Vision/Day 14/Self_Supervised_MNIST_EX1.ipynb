{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "06760dc6",
      "metadata": {
        "id": "06760dc6"
      },
      "source": [
        "# 🧠Self-Supervised Learning Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f354b321",
      "metadata": {
        "id": "f354b321"
      },
      "source": [
        "\n",
        "This notebook is based on a self-supervised learning exercise using MNIST and PyTorch.\n",
        "\n",
        "You will:\n",
        "- Build and train an **autoencoder** for representation learning.\n",
        "- Use **2% labeled data** to train a classifier on the learned representations.\n",
        "- Evaluate the model and visualize latent space.\n",
        "\n",
        "📝 Some code cells include `# TODO` comments. Complete them as you go!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c575e2f",
      "metadata": {
        "id": "1c575e2f"
      },
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19656d69",
      "metadata": {
        "id": "19656d69"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.manifold import TSNE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set device and random seeds\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# MNIST digit classes\n",
        "MNIST_CLASSES = list(range(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acc45d98",
      "metadata": {
        "id": "acc45d98"
      },
      "source": [
        "## 2. Prepare and Visualize Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34618703",
      "metadata": {
        "id": "34618703"
      },
      "outputs": [],
      "source": [
        "def prepare_ssl_datasets(labeled_percentage=0.02):\n",
        "    \"\"\"Prepare datasets for self-supervised learning\"\"\"\n",
        "\n",
        "    # TODO: Define transforms for MNIST\n",
        "    # For autoencoders, we typically normalize to [0, 1] or [-1, 1]\n",
        "    # YOUR CODE HERE:\n",
        "\n",
        "\n",
        "    # Load MNIST datasets\n",
        "    train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    # Create unlabeled dataset (all training data, labels ignored)\n",
        "    unlabeled_dataset = train_dataset\n",
        "\n",
        "    # Create small labeled dataset (2% of training data)\n",
        "    num_labeled = int(len(train_dataset) * labeled_percentage)\n",
        "\n",
        "    # Get indices for each class\n",
        "    class_indices = {i: [] for i in range(10)}\n",
        "    for idx, (_, label) in enumerate(train_dataset):\n",
        "        class_indices[label].append(idx)\n",
        "\n",
        "    # Sample equally from each class\n",
        "    samples_per_class = num_labeled // 10\n",
        "    labeled_indices = []\n",
        "\n",
        "    for class_idx in range(10):\n",
        "        class_samples = np.random.choice(\n",
        "            class_indices[class_idx],\n",
        "            samples_per_class,\n",
        "            replace=False\n",
        "        )\n",
        "        labeled_indices.extend(class_samples)\n",
        "\n",
        "    # Create labeled subset\n",
        "    labeled_dataset = Subset(train_dataset, labeled_indices)\n",
        "\n",
        "    print(f\"Unlabeled dataset size: {len(unlabeled_dataset)} (labels ignored)\")\n",
        "    print(f\"Labeled dataset size: {len(labeled_dataset)} ({labeled_percentage*100:.1f}%)\")\n",
        "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "    print(f\"Samples per class in labeled set: {samples_per_class}\")\n",
        "\n",
        "    return unlabeled_dataset, labeled_dataset, test_dataset\n",
        "\n",
        "def visualize_mnist_samples(dataset, title=\"MNIST Samples\", num_samples=20):\n",
        "    \"\"\"Visualize sample images from MNIST\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(2, 10, figsize=(15, 4))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    # Get random samples\n",
        "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        if hasattr(dataset, 'dataset'):  # Handle Subset\n",
        "            image, label = dataset.dataset[dataset.indices[idx]]\n",
        "        else:\n",
        "            image, label = dataset[idx]\n",
        "\n",
        "        axes[i].imshow(image.squeeze(), cmap='gray')\n",
        "        axes[i].set_title(f'Label: {label}')\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def analyze_class_distribution(dataset, title=\"Class Distribution\"):\n",
        "    \"\"\"Analyze class distribution in the dataset\"\"\"\n",
        "\n",
        "    class_counts = [0] * 10\n",
        "\n",
        "    # Count classes\n",
        "    if hasattr(dataset, 'dataset'):  # Handle Subset\n",
        "        for idx in dataset.indices:\n",
        "            _, label = dataset.dataset[idx]\n",
        "            class_counts[label] += 1\n",
        "    else:\n",
        "        for _, label in dataset:\n",
        "            class_counts[label] += 1\n",
        "\n",
        "    # Plot distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    bars = plt.bar(range(10), class_counts, color='skyblue', alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Digit Class')\n",
        "    plt.ylabel('Number of Samples')\n",
        "    plt.xticks(range(10))\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, count in zip(bars, class_counts):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
        "                str(count), ha='center', va='bottom')\n",
        "\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Class distribution:\")\n",
        "    for i, count in enumerate(class_counts):\n",
        "        print(f\"Digit {i}: {count} samples\")\n",
        "\n",
        "# Prepare datasets\n",
        "unlabeled_dataset, labeled_dataset, test_dataset = prepare_ssl_datasets(labeled_percentage=0.02)\n",
        "\n",
        "# Visualize data\n",
        "visualize_mnist_samples(unlabeled_dataset, \"Unlabeled MNIST Samples\")\n",
        "visualize_mnist_samples(labeled_dataset, \"Labeled MNIST Samples (2%)\")\n",
        "\n",
        "# Analyze distributions\n",
        "analyze_class_distribution(labeled_dataset, \"Labeled Dataset Distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87ef23a3",
      "metadata": {
        "id": "87ef23a3"
      },
      "source": [
        "## 3. Define Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a510c784",
      "metadata": {
        "id": "a510c784"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"Encoder network that compresses input to latent representation\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=784, latent_dim=128):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        # TODO: Define encoder architecture\n",
        "        # Progressively reduce dimensionality: 784 -> ... -> latent_dim\n",
        "        # Try different cnn tecniques (dropout,batchnorm)\n",
        "        # YOUR CODE HERE:\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            # Note: No activation on final layer - let it learn any range\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement encoder forward pass\n",
        "        # YOUR CODE HERE:\n",
        "\n",
        "        # Flatten input if needed\n",
        "        if len(x.shape) > 2:\n",
        "            x = x.view(x.size(0), -1)\n",
        "\n",
        "        return\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"Decoder network that reconstructs input from latent representation\"\"\"\n",
        "\n",
        "    def __init__(self, latent_dim=128, output_dim=784):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        # TODO: Define decoder architecture\n",
        "        # Progressively increase dimensionality: latent_dim -> ... -> 784\n",
        "        # YOUR CODE HERE:\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            # First layer: expand from latent_dim to 128\n",
        "            # Use batchnorm1d after activation function\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement decoder forward pass\n",
        "        # YOUR CODE HERE:\n",
        "\n",
        "        return\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    \"\"\"Complete autoencoder combining encoder and decoder\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=784, latent_dim=128):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # TODO: Combine encoder and decoder\n",
        "        # YOUR CODE HERE:\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement autoencoder forward pass\n",
        "        # YOUR CODE HERE:\n",
        "\n",
        "        return reconstructed, latent\n",
        "\n",
        "    def encode(self, x):\n",
        "        \"\"\"Get latent representation only\"\"\"\n",
        "        return self.encoder(x)\n",
        "\n",
        "# Test autoencoder\n",
        "latent_dim = 128\n",
        "autoencoder = Autoencoder(input_dim=784, latent_dim=latent_dim)\n",
        "\n",
        "# Test with dummy data\n",
        "test_input = torch.randn(32, 784)  # Batch of flattened MNIST images\n",
        "reconstructed, latent = autoencoder(test_input)\n",
        "\n",
        "print(f\"Input shape: {test_input.shape}\")\n",
        "print(f\"Latent representation shape: {latent.shape}\")\n",
        "print(f\"Reconstructed output shape: {reconstructed.shape}\")\n",
        "print(f\"Compression ratio: {784/latent_dim:.1f}x\")\n",
        "\n",
        "# Count parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Autoencoder parameters: {count_parameters(autoencoder):,}\")\n",
        "print(f\"Encoder parameters: {count_parameters(autoencoder.encoder):,}\")\n",
        "print(f\"Decoder parameters: {count_parameters(autoencoder.decoder):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3bdae2b",
      "metadata": {
        "id": "b3bdae2b"
      },
      "source": [
        "## 4. Train Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2e2dedc",
      "metadata": {
        "id": "b2e2dedc"
      },
      "outputs": [],
      "source": [
        "def train_autoencoder(model, unlabeled_loader, num_epochs=50, learning_rate=1e-3):\n",
        "    \"\"\"Train autoencoder on unlabeled data\"\"\"\n",
        "\n",
        "    # Setup training components for autoencoder\n",
        "\n",
        "    criterion = nn.MSELoss()  # Reconstruction loss\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    train_losses = []\n",
        "\n",
        "    print(\"Starting Autoencoder pretraining...\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        for batch_idx, (images, _) in enumerate(unlabeled_loader):  # Ignore labels!\n",
        "\n",
        "            images = images.to(device)\n",
        "            batch_size = images.size(0)\n",
        "\n",
        "            # Flatten images\n",
        "            images_flat = images.view(batch_size, -1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            reconstructed, latent =\n",
        "\n",
        "            # Calculate reconstruction loss\n",
        "            loss =\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            # Print progress\n",
        "            if batch_idx % 200 == 0:\n",
        "                print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}, Loss: {loss.item():.6f}')\n",
        "\n",
        "        # Calculate average loss\n",
        "        avg_loss = epoch_loss / num_batches\n",
        "        train_losses.append(avg_loss)\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.6f}, LR: {scheduler.get_last_lr()[0]:.6f}')\n",
        "        print('-' * 60)\n",
        "\n",
        "    print(\"Autoencoder pretraining completed!\")\n",
        "    return train_losses\n",
        "\n",
        "def visualize_reconstructions(model, dataset, num_samples=10):\n",
        "    \"\"\"Visualize original images and their reconstructions\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Get random samples\n",
        "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "\n",
        "    fig, axes = plt.subplots(2, num_samples, figsize=(15, 4))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, idx in enumerate(indices):\n",
        "            # Get original image\n",
        "            if hasattr(dataset, 'dataset'):\n",
        "                original, label = dataset.dataset[dataset.indices[idx]]\n",
        "            else:\n",
        "                original, label = dataset[idx]\n",
        "\n",
        "            # Reconstruct image\n",
        "            original_flat = original.view(1, -1).to(device)\n",
        "            reconstructed, _ = model(original_flat)\n",
        "            reconstructed = reconstructed.view(28, 28).cpu()\n",
        "\n",
        "            # Plot original\n",
        "            axes[0, i].imshow(original.squeeze(), cmap='gray')\n",
        "            axes[0, i].set_title(f'Original: {label}')\n",
        "            axes[0, i].axis('off')\n",
        "\n",
        "            # Plot reconstruction\n",
        "            axes[1, i].imshow(reconstructed, cmap='gray')\n",
        "            axes[1, i].set_title('Reconstructed')\n",
        "            axes[1, i].axis('off')\n",
        "\n",
        "    plt.suptitle('Original vs Reconstructed Images')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_training_progress(train_losses):\n",
        "    \"\"\"Plot autoencoder training loss\"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_losses, color='blue', linewidth=2)\n",
        "    plt.title('Autoencoder Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('MSE Loss')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Final training loss: {train_losses[-1]:.6f}\")\n",
        "    print(f\"Loss reduction: {train_losses[0]/train_losses[-1]:.2f}x\")\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 256\n",
        "\n",
        "unlabeled_loader = DataLoader(\n",
        "    unlabeled_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(f\"Unlabeled data batches: {len(unlabeled_loader)}\")\n",
        "\n",
        "# Create and train autoencoder\n",
        "autoencoder = Autoencoder(input_dim=784, latent_dim=128)\n",
        "\n",
        "train_losses = train_autoencoder(autoencoder, unlabeled_loader, num_epochs=30)\n",
        "\n",
        "plot_training_progress(train_losses)\n",
        "visualize_reconstructions(autoencoder, unlabeled_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e033afd",
      "metadata": {
        "id": "2e033afd"
      },
      "source": [
        "## 5. Latent Space Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f826eb8",
      "metadata": {
        "id": "7f826eb8"
      },
      "outputs": [],
      "source": [
        "def extract_latent_representations(model, dataset, max_samples=5000):\n",
        "    \"\"\"Extract latent representations and labels for analysis\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    latent_vectors = []\n",
        "    labels = []\n",
        "\n",
        "    # Create data loader\n",
        "    loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, batch_labels in loader:\n",
        "            if len(latent_vectors) * 128 >= max_samples:\n",
        "                break\n",
        "\n",
        "            images = images.to(device)\n",
        "            images_flat = images.view(images.size(0), -1)\n",
        "\n",
        "            # Get latent representations\n",
        "            latent = model.encode(images_flat)\n",
        "\n",
        "            latent_vectors.append(latent.cpu())\n",
        "            labels.extend(batch_labels.numpy())\n",
        "\n",
        "    latent_vectors = torch.cat(latent_vectors, dim=0).numpy()\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return latent_vectors[:max_samples], labels[:max_samples]\n",
        "\n",
        "def visualize_latent_space(latent_vectors, labels, method='tsne'):\n",
        "    \"\"\"Visualize latent space using dimensionality reduction\"\"\"\n",
        "\n",
        "    if method == 'tsne':\n",
        "\n",
        "        print(\"Applying t-SNE to latent representations...\")\n",
        "        tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "        latent_2d = tsne.fit_transform(latent_vectors)\n",
        "\n",
        "    elif method == 'pca':\n",
        "        from sklearn.decomposition import PCA\n",
        "\n",
        "        print(\"Applying PCA to latent representations...\")\n",
        "        pca = PCA(n_components=2, random_state=42)\n",
        "        latent_2d = pca.fit_transform(latent_vectors)\n",
        "\n",
        "        print(f\"PCA explained variance ratio: {pca.explained_variance_ratio_}\")\n",
        "\n",
        "    # Plot the 2D representation\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # Create color map for digits\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
        "\n",
        "    for digit in range(10):\n",
        "        mask = labels == digit\n",
        "        plt.scatter(latent_2d[mask, 0], latent_2d[mask, 1],\n",
        "                   c=[colors[digit]], label=f'Digit {digit}', alpha=0.6, s=20)\n",
        "\n",
        "    plt.title(f'Latent Space Visualization ({method.upper()})')\n",
        "    plt.xlabel('Component 1')\n",
        "    plt.ylabel('Component 2')\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def analyze_latent_space_structure(latent_vectors, labels):\n",
        "    \"\"\"Analyze the structure of the learned latent space\"\"\"\n",
        "\n",
        "    # Calculate inter-class and intra-class distances\n",
        "    from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "    inter_class_distances = []\n",
        "    intra_class_distances = []\n",
        "\n",
        "    for digit in range(10):\n",
        "        # Get samples for this digit\n",
        "        digit_mask = labels == digit\n",
        "        digit_latents = latent_vectors[digit_mask]\n",
        "\n",
        "        if len(digit_latents) > 1:\n",
        "            # Intra-class distances (within same digit)\n",
        "            intra_distances = pdist(digit_latents)\n",
        "            intra_class_distances.extend(intra_distances)\n",
        "\n",
        "        # Inter-class distances (between different digits)\n",
        "        for other_digit in range(digit + 1, 10):\n",
        "            other_mask = labels == other_digit\n",
        "            other_latents = latent_vectors[other_mask]\n",
        "\n",
        "            if len(other_latents) > 0:\n",
        "                # Calculate distances between all pairs\n",
        "                for d1 in digit_latents[:50]:  # Sample to avoid too many calculations\n",
        "                    for d2 in other_latents[:50]:\n",
        "                        distance = np.linalg.norm(d1 - d2)\n",
        "                        inter_class_distances.append(distance)\n",
        "\n",
        "    # Plot distance distributions\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(intra_class_distances, bins=50, alpha=0.7, color='blue', density=True)\n",
        "    plt.title('Intra-class Distances')\n",
        "    plt.xlabel('Distance')\n",
        "    plt.ylabel('Density')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(inter_class_distances, bins=50, alpha=0.7, color='red', density=True)\n",
        "    plt.title('Inter-class Distances')\n",
        "    plt.xlabel('Distance')\n",
        "    plt.ylabel('Density')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Average intra-class distance: {np.mean(intra_class_distances):.4f}\")\n",
        "    print(f\"Average inter-class distance: {np.mean(inter_class_distances):.4f}\")\n",
        "    print(f\"Separation ratio: {np.mean(inter_class_distances) / np.mean(intra_class_distances):.4f}\")\n",
        "\n",
        "print(\"Extracting latent representations...\")\n",
        "latent_vectors, labels = extract_latent_representations(autoencoder, test_dataset)\n",
        "#\n",
        "print(f\"Extracted {len(latent_vectors)} latent representations\")\n",
        "print(f\"Latent dimension: {latent_vectors.shape[1]}\")\n",
        "#\n",
        "# # Visualize latent space\n",
        "visualize_latent_space(latent_vectors, labels, method='tsne')\n",
        "visualize_latent_space(latent_vectors, labels, method='pca')\n",
        "#\n",
        "# # Analyze latent space structure\n",
        "analyze_latent_space_structure(latent_vectors, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7c21c85",
      "metadata": {
        "id": "a7c21c85"
      },
      "source": [
        "## 6. Classifier Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ab17842",
      "metadata": {
        "id": "1ab17842"
      },
      "outputs": [],
      "source": [
        "class SupervisedClassifier(nn.Module):\n",
        "    \"\"\"Classifier that uses pretrained encoder + classification head\"\"\"\n",
        "\n",
        "    def __init__(self, encoder, num_classes=10, freeze_encoder=False):\n",
        "        super(SupervisedClassifier, self).__init__()\n",
        "\n",
        "        # TODO: Use pretrained encoder and add classification head\n",
        "        # YOUR CODE HERE:\n",
        "\n",
        "        self.encoder = encoder\n",
        "\n",
        "        # Freeze encoder weights if specified\n",
        "        if freeze_encoder:\n",
        "            for param in self.encoder.parameters():\n",
        "                param.requires_grad = False\n",
        "            print(\"Encoder weights frozen\")\n",
        "        else:\n",
        "            print(\"Encoder weights will be fine-tuned\")\n",
        "\n",
        "        # Add classification head\n",
        "        # Assuming encoder outputs latent_dim features\n",
        "        latent_dim = 128  # Should match encoder output\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "          .....\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement forward pass\n",
        "        # YOUR CODE HERE:\n",
        "\n",
        "        # Extract features using pretrained encoder\n",
        "\n",
        "        return logits\n",
        "\n",
        "def train_classifier(model, train_loader, val_loader, num_epochs=50, learning_rate=1e-3):\n",
        "    \"\"\"Train classifier with limited labeled data\"\"\"\n",
        "\n",
        "    # TODO: Setup training for classification\n",
        "    # YOUR CODE HERE:\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.7)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    best_val_acc = 0\n",
        "\n",
        "    print(\"Starting supervised fine-tuning...\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            # TODO: Implement training step\n",
        "            # YOUR CODE HERE:\n",
        "\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            batch_size = images.size(0)\n",
        "\n",
        "            # Flatten images\n",
        "            images_flat = images.view(batch_size, -1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            logits =\n",
        "            loss =\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            epoch_loss += loss.item()\n",
        "            _, predicted = torch.max(logits.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                images_flat = images.view(images.size(0), -1)\n",
        "\n",
        "                logits = model(images_flat)\n",
        "                _, predicted = torch.max(logits.data, 1)\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate metrics\n",
        "        train_acc = 100 * correct_train / total_train\n",
        "        val_acc = 100 * correct_val / total_val\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "        train_losses.append(avg_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_ssl_classifier.pth')\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "            print(f'Train Loss: {avg_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "            print(f'Val Acc: {val_acc:.2f}%, Best Val Acc: {best_val_acc:.2f}%')\n",
        "            print('-' * 60)\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(torch.load('best_ssl_classifier.pth'))\n",
        "\n",
        "    print(f\"Fine-tuning completed! Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "    return train_losses, train_accuracies, val_accuracies\n",
        "\n",
        "def evaluate_classifier(model, test_loader):\n",
        "    \"\"\"Evaluate classifier on test set\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            images_flat = images.view(images.size(0), -1)\n",
        "\n",
        "            logits = model(images_flat)\n",
        "            _, predicted = torch.max(logits.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    # Detailed classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(true_labels, predictions,\n",
        "                              target_names=[f'Digit {i}' for i in range(10)]))\n",
        "\n",
        "    return accuracy, predictions, true_labels\n",
        "\n",
        "# Create data loaders for supervised training\n",
        "labeled_loader = DataLoader(labeled_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Split labeled data into train/val\n",
        "val_split = 0.2\n",
        "val_size = int(len(labeled_dataset) * val_split)\n",
        "train_size = len(labeled_dataset) - val_size\n",
        "\n",
        "labeled_train, labeled_val = random_split(labeled_dataset, [train_size, val_size])\n",
        "\n",
        "labeled_train_loader = DataLoader(labeled_train, batch_size=32, shuffle=True)\n",
        "labeled_val_loader = DataLoader(labeled_val, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Labeled training samples: {len(labeled_train)}\")\n",
        "print(f\"Labeled validation samples: {len(labeled_val)}\")\n",
        "\n",
        "ssl_classifier = SupervisedClassifier(autoencoder.encoder, num_classes=10, freeze_encoder=False)\n",
        "\n",
        "ssl_train_losses, ssl_train_accs, ssl_val_accs = train_classifier(\n",
        " ssl_classifier, labeled_train_loader, labeled_val_loader, num_epochs=50\n",
        ")\n",
        "\n",
        "ssl_test_accuracy, ssl_predictions, ssl_true_labels = evaluate_classifier(ssl_classifier, test_loader)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}