{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![image.png](https://i.imgur.com/a3uAqnb.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPXksRDVqcQP"
      },
      "source": [
        "# Generative Adversarial Networks (GANs) - MNIST Image Generation\n",
        "\n",
        "Welcome to this hands-on exercise on Generative Adversarial Networks (GANs)! You'll build a GAN from scratch to generate handwritten digits similar to the MNIST dataset.\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand GAN architecture and training dynamics\n",
        "- Implement Generator and Discriminator networks\n",
        "- Learn adversarial training process\n",
        "- Visualize and analyze results\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Introduction to GANs\n",
        "\n",
        "GANs consist of two neural networks competing against each other:\n",
        "- **Generator**: Creates fake data from random noise\n",
        "- **Discriminator**: Distinguishes between real and fake data\n",
        "\n",
        "The generator tries to fool the discriminator, while the discriminator tries to correctly identify fake data. This adversarial process leads to increasingly realistic generated data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDMlHfyHqXKV",
        "outputId": "0f472da8-44fd-44b0-a4df-0fba166e5db8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8pufardqu7A",
        "outputId": "66591ffd-8b70-4569-db24-0d788ee3337d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 6.05MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 160kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.44MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.53MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size: 60000\n",
            "Number of batches: 938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # TODO: Add normalization transform to scale pixel values to [-1, 1]\n",
        "    # Hint: Use transforms.Normalize with mean=0.5, std=0.5\n",
        "    # YOUR CODE HERE:\n",
        "\n",
        "])\n",
        "\n",
        "# TODO: Complete the dataset loading\n",
        "# YOUR CODE HERE:\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root='/content/', train=True, download=True, transform=None\n",
        ")\n",
        "\n",
        "# Create data loader\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(f\"Dataset size: {len(train_dataset)}\")\n",
        "print(f\"Number of batches: {len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6vxkALssMLI"
      },
      "source": [
        "**Question**: Why do we normalize to [-1, 1] instead of [0, 1]?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNUpYTsUscnd"
      },
      "source": [
        "The Generator takes random noise as input and transforms it into fake images. It learns to map from the noise space to the data space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPgtx0V0rqgp"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_dim=100, img_dim=28*28):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # TODO: Define the generator architecture\n",
        "        # The generator should transform noise (noise_dim) into images (img_dim)\n",
        "        # Use a series of Linear layers with appropriate activations\n",
        "        # Suggested architecture: noise_dim -> 256 -> 512 -> 1024 -> img_dim\n",
        "        # YOUR CODE HERE:\n",
        "        self.model = nn.Sequential(\n",
        "            # Layer 1: noise_dim -> 256\n",
        "            # Hint: Use nn.Linear followed by nn.LeakyReLU(0.2)\n",
        "\n",
        "            # Layer 2: 256 -> 512\n",
        "\n",
        "            # Layer 3: 512 -> 1024\n",
        "\n",
        "            # Output layer: 1024 -> img_dim\n",
        "            # Use Tanh activation for final layer to output values in [-1, 1]\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement forward pass\n",
        "        # YOUR CODE HERE:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBdHsuAOsHuU"
      },
      "source": [
        "**Question**: Why do we use Tanh activation in the generator's output layer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXcE4TW9sU8U"
      },
      "source": [
        "The Discriminator is a binary classifier that distinguishes between real and fake images. It outputs a probability that the input image is real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rj4WBvG-sIPn"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_dim=28*28):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # TODO: Define the discriminator architecture\n",
        "        # The discriminator should classify images as real (1) or fake (0)\n",
        "        # Architecture: img_dim -> 1024 -> 512 -> 256 -> 1\n",
        "        # YOUR CODE HERE:\n",
        "        self.model = nn.Sequential(\n",
        "            # Layer 1: img_dim -> 1024\n",
        "            # Hint: Use nn.Linear followed by nn.LeakyReLU(0.2)\n",
        "\n",
        "            # Layer 2: 1024 -> 512\n",
        "\n",
        "            # Layer 3: 512 -> 256\n",
        "\n",
        "            # Output layer: 256 -> 1\n",
        "            # Use Sigmoid for binary classification\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement forward pass\n",
        "        # YOUR CODE HERE:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uLZsS3LvA_6"
      },
      "source": [
        "Initialize Networks and Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE2aR_JpsvOh"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "noise_dim = 100\n",
        "learning_rate = 0.0002\n",
        "\n",
        "# TODO: Create instances of Generator and Discriminator\n",
        "# YOUR CODE HERE:\n",
        "generator =\n",
        "discriminator =\n",
        "\n",
        "# Move models to device\n",
        "generator.to(device)\n",
        "discriminator.to(device)\n",
        "\n",
        "# TODO: Define loss function and optimizers\n",
        "# Use Binary Cross Entropy Loss and Adam optimizer\n",
        "# YOUR CODE HERE:\n",
        "criterion =\n",
        "gen_optimizer =\n",
        "disc_optimizer =\n",
        "\n",
        "print(\"Models initialized successfully!\")\n",
        "print(f\"Generator parameters: {sum(p.numel() for p in generator.parameters())}\")\n",
        "print(f\"Discriminator parameters: {sum(p.numel() for p in discriminator.parameters())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfemnKBHvEkk"
      },
      "source": [
        "Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPGCnLsYs53m"
      },
      "outputs": [],
      "source": [
        "def train_gan(generator, discriminator, train_loader, num_epochs=50):\n",
        "    \"\"\"\n",
        "    Train the GAN for specified number of epochs\n",
        "    \"\"\"\n",
        "\n",
        "    # Lists to store losses for plotting\n",
        "    gen_losses = []\n",
        "    disc_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        gen_epoch_loss = 0\n",
        "        disc_epoch_loss = 0\n",
        "\n",
        "        for batch_idx, (real_images, _) in enumerate(train_loader):\n",
        "            batch_size = real_images.size(0)\n",
        "\n",
        "            # Flatten images and move to device\n",
        "            real_images = real_images.view(batch_size, -1).to(device)\n",
        "\n",
        "            # Create labels\n",
        "            real_labels = torch.ones(batch_size, 1).to(device)\n",
        "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "            # =================================================================\n",
        "            # TRAIN DISCRIMINATOR\n",
        "            # =================================================================\n",
        "\n",
        "            disc_optimizer.zero_grad()\n",
        "\n",
        "            # Train on real images\n",
        "            # TODO: Get discriminator output for real images and calculate loss\n",
        "            # YOUR CODE HERE:\n",
        "            real_output =\n",
        "            real_loss =\n",
        "\n",
        "            # Train on fake images\n",
        "            # TODO: Generate fake images and get discriminator output\n",
        "            # YOUR CODE HERE:\n",
        "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
        "            fake_images = generator(noise).detach()\n",
        "            fake_output =\n",
        "            fake_loss =\n",
        "\n",
        "            # Total discriminator loss\n",
        "            # TODO: Calculate total discriminator loss and backpropagate\n",
        "            # YOUR CODE HERE:\n",
        "            disc_loss =\n",
        "            disc_loss.backward()\n",
        "            disc_optimizer.step()\n",
        "\n",
        "            # =================================================================\n",
        "            # TRAIN GENERATOR\n",
        "            # =================================================================\n",
        "\n",
        "            gen_optimizer.zero_grad()\n",
        "\n",
        "            # TODO: Train generator by trying to fool discriminator\n",
        "            # Generate new fake images and get discriminator output\n",
        "            # Calculate loss using real_labels (we want discriminator to think fake images are real)\n",
        "            # YOUR CODE HERE:\n",
        "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
        "            fake_images = generator(noise)\n",
        "            fake_output =\n",
        "            # Use real_labels because we want discriminator to think fake images are real\n",
        "            gen_loss =\n",
        "\n",
        "            gen_loss.backward()\n",
        "            gen_optimizer.step()\n",
        "\n",
        "            # Accumulate losses\n",
        "            gen_epoch_loss += gen_loss.item()\n",
        "            disc_epoch_loss += disc_loss.item()\n",
        "\n",
        "        # Average losses for the epoch\n",
        "        gen_epoch_loss /= len(train_loader)\n",
        "        disc_epoch_loss /= len(train_loader)\n",
        "\n",
        "        gen_losses.append(gen_epoch_loss)\n",
        "        disc_losses.append(disc_epoch_loss)\n",
        "\n",
        "        # Print progress\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "            print(f'Generator Loss: {gen_epoch_loss:.4f}')\n",
        "            print(f'Discriminator Loss: {disc_epoch_loss:.4f}')\n",
        "            print('-' * 50)\n",
        "\n",
        "    return gen_losses, disc_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glr6N4vSvHZ8"
      },
      "source": [
        "Visualization Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGv-GULptAjt"
      },
      "outputs": [],
      "source": [
        "def plot_losses(gen_losses, disc_losses):\n",
        "    \"\"\"Plot training losses\"\"\"\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(gen_losses, label='Generator Loss')\n",
        "    plt.plot(disc_losses, label='Discriminator Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('GAN Training Losses')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def generate_and_display_images(generator, num_images=16):\n",
        "    \"\"\"Generate and display fake images\"\"\"\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn(num_images, noise_dim).to(device)\n",
        "        fake_images = generator(noise)\n",
        "\n",
        "        # Reshape images for display\n",
        "        fake_images = fake_images.view(fake_images.size(0), 28, 28)\n",
        "        fake_images = fake_images.cpu().numpy()\n",
        "\n",
        "        # Create subplot\n",
        "        fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
        "        for i, ax in enumerate(axes.flat):\n",
        "            if i < num_images:\n",
        "                ax.imshow(fake_images[i], cmap='gray')\n",
        "                ax.axis('off')\n",
        "\n",
        "        plt.suptitle('Generated Images')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def compare_real_vs_fake(train_loader, generator, num_images=8):\n",
        "    \"\"\"Compare real and generated images side by side\"\"\"\n",
        "    # Get real images\n",
        "    real_images = next(iter(train_loader))[0][:num_images]\n",
        "\n",
        "    # Generate fake images\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        # SOLUTION: Generate fake images\n",
        "        noise = torch.randn(num_images, noise_dim).to(device)\n",
        "        fake_images = generator(noise)\n",
        "        fake_images = fake_images.view(fake_images.size(0), 28, 28)\n",
        "\n",
        "    # Plot comparison\n",
        "    fig, axes = plt.subplots(2, num_images, figsize=(12, 4))\n",
        "\n",
        "    for i in range(num_images):\n",
        "        # Real images\n",
        "        axes[0, i].imshow(real_images[i].squeeze(), cmap='gray')\n",
        "        axes[0, i].set_title('Real' if i == 0 else '')\n",
        "        axes[0, i].axis('off')\n",
        "\n",
        "        # Fake images\n",
        "        axes[1, i].imshow(fake_images[i].cpu().numpy(), cmap='gray')\n",
        "        axes[1, i].set_title('Generated' if i == 0 else '')\n",
        "        axes[1, i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj5xP6NTvJ2f"
      },
      "source": [
        "Training Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "he43WhO7tBIZ"
      },
      "outputs": [],
      "source": [
        "gen_losses, disc_losses = train_gan(generator, discriminator, train_loader, num_epochs=50)\n",
        "\n",
        "print(\"Training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQhZdO-kvL3p"
      },
      "source": [
        "Results and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OICCuPLPtO8M"
      },
      "outputs": [],
      "source": [
        "plot_losses(gen_losses, disc_losses)\n",
        "\n",
        "# Generate and display sample images\n",
        "print(\"Generated Images:\")\n",
        "generate_and_display_images(generator)\n",
        "\n",
        "\n",
        "# Compare real vs fake images\n",
        "print(\"Real vs Generated Images Comparison:\")\n",
        "compare_real_vs_fake(train_loader, generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Contributed by: Abdullah Jan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![image.png](https://i.imgur.com/a3uAqnb.png)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
